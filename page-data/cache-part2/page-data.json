{"componentChunkName":"component---src-templates-blog-post-js","path":"/cache-part2/","result":{"data":{"site":{"siteMetadata":{"title":"GoToBill"}},"markdownRemark":{"id":"c562831f-2840-545a-9e1c-fdd33dc31eeb","excerpt":"이 글은 Facebook Memcached 아키텍처 (1탄)의 후속편입니다. 이 글은 Facebook의 공식 논문 Scaling Memcache at Facebook을 기반으로 작성되었습니다. 지역 내 확장: 데이터 복제 트래픽 증가에 따라 더 많은 웹 및 Memcached…","html":"<p>이 글은 <a href=\"../cache-part1\">Facebook Memcached 아키텍처 (1탄)</a>의 후속편입니다.</p>\n<p>이 글은 Facebook의 공식 논문 <a href=\"https://research.facebook.com/publications/scaling-memcache-at-facebook/\">Scaling Memcache at Facebook</a>을 기반으로 작성되었습니다.</p>\n<h2>지역 내 확장: 데이터 복제</h2>\n<p>트래픽 증가에 따라 더 많은 웹 및 Memcached 서버를 추가하는 것만으로는 모든 문제를 해결할 수 없습니다. 더 많은 웹서버가 추가될수록 요청이 많은 아이템은 더욱 인기가 높아지고, Memcached 서버 수가 증가하면 Incast Congestion도 악화됩니다.</p>\n<p>Facebook은 웹 및 Memcached 서버를 여러 <strong>Frontend Cluster</strong>로 분할했습니다. 이러한 클러스터와 데이터베이스를 포함하는 Storage Cluster가 함께 <strong>Region</strong>을 정의합니다.</p>\n<p><strong>Region 아키텍처의 이점</strong></p>\n<p><strong>1. 더 작은 장애 도메인</strong></p>\n<ul>\n<li>한 Frontend Cluster에 장애가 발생해도 다른 Cluster는 영향받지 않음</li>\n<li>장애 범위가 전체 시스템이 아닌 하나의 Cluster로 제한됨</li>\n</ul>\n<p><strong>2. 다루기 쉬운 네트워크 구성</strong></p>\n<ul>\n<li>각 Cluster가 독립적으로 관리되어 네트워크 설정이 단순해짐</li>\n<li>대규모 단일 클러스터보다 관리와 문제 해결이 쉬움</li>\n</ul>\n<p><strong>3. Incast Congestion 감소</strong></p>\n<ul>\n<li>단일 거대 클러스터에서는 수백 대의 Memcached 서버가 동시에 응답을 보냄</li>\n<li>여러 작은 Cluster로 나누면 각 웹서버가 통신하는 Memcached 서버 수가 줄어듦</li>\n<li>동시 응답 수가 감소하여 네트워크 정체 현상 완화</li>\n</ul>\n<p><strong>4. 데이터 복제로 인한 독립적인 장애 도메인</strong></p>\n<ul>\n<li>각 Frontend Cluster가 독립적인 Memcached를 가짐</li>\n<li>같은 인기 데이터(예: 유명인 게시물)가 여러 Cluster의 캐시에 각각 복제되어 저장됨</li>\n<li>Cluster A 장애 시에도 Cluster B는 자신의 캐시 복사본으로 계속 서비스 가능</li>\n</ul>\n<h3>지역 무효화 (Regional Invalidations)</h3>\n<p>Region의 Storage Cluster(MySQL)는 데이터의 <strong>원본</strong>을 보유합니다. 사용자 요청에 따라 이 데이터가 여러 Frontend Cluster의 Memcached에 복제되어 캐시됩니다.</p>\n<p>Storage Cluster는 원본 데이터가 변경되면 모든 <strong>Frontend Cluster의 캐시된 복사본</strong>을 <strong>무효화</strong>(invalidate)하여 일관성을 유지할 책임이 있습니다.</p>\n<h4>mcsqueal 데몬</h4>\n<p>원본 데이터(DB)를 수정하는 SQL 문은 트랜잭션이 커밋되면 무효화해야 할 Memcache 키를 포함하도록 수정됩니다.</p>\n<p>모든 MySQL 데이터베이스에 <strong>mcsqueal 데몬</strong>이 배포됩니다. 이 데몬은 <strong>CDC(Change Data Capture)</strong> 방식으로 동작합니다.</p>\n<p><strong>CDC란?</strong></p>\n<p>모든 현대적인 데이터베이스(Oracle, MySQL 등)는 데이터의 변경 이력을 안정적으로 기록하고 관리하기 위한 <strong>트랜잭션 로그</strong>(Transaction Log)를 가지고 있습니다.</p>\n<p><strong>CDC는 바로 이 데이터베이스의 핵심 기능을 활용</strong>하여 애플리케이션과 완전히 분리되어, 데이터베이스의 <strong>트랜잭션 로그를 직접 읽는 방식으로 동작</strong>합니다.</p>\n<p>이를 통해 데이터베이스는 데이터가 변경되면 그 변경 내용을 통지하는 기능을 제공합니다.</p>\n<p><strong>mcsqueal의 동작 방식:</strong></p>\n<ul>\n<li><strong>MySQL의 Commit Log를 실시간으로 모니터링</strong></li>\n<li>커밋된 SQL 문을 검사하여 무효화할 키(DELETE) 추출</li>\n<li><strong>해당 Region의 모든 Frontend Cluster에 무효화 명령 브로드캐스트</strong></li>\n</ul>\n<p><strong>DELETE 명령의 이중 효과:</strong></p>\n<p>mcsqueal이 보내는 DELETE 명령은 단순히 캐시 데이터만 삭제하는 것이 아닙니다:</p>\n<ol>\n<li><strong>기존 캐시 데이터 삭제</strong></li>\n<li><strong>해당 키에 발급된 모든 outstanding lease 무효화</strong></li>\n</ol>\n<p>이를 통해 Race Condition을 방지합니다:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">문제 상황:\n1. 클라이언트 A: 캐시 미스 → lease 획득\n2. 클라이언트 A: DB에서 데이터 읽음 (user:1 = \"Alice\")\n3. 클라이언트 B: DB 업데이트 (user:1 = \"Bob\")\n4. mcsqueal: DELETE 명령 브로드캐스트 → lease 무효화\n5. 클라이언트 A: stale data를 set 시도 → lease가 무효화되어 set 실패\n\n결과: stale data가 캐시에 들어가지 않음</code></pre></div>\n<p><strong>무효화 파이프라인</strong></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8b9cc074b2fc52b77cb43ed2bf2a5a30/60b3a/inval.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 44.30379746835443%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABiklEQVR42m2RW2+bQBBG+f+/pM99dyulatWHRk7aylVJjInNbbkYWK5mYU/XhjSpm0GjDzE7H3NmLUyIEtZP+vzKNMsltHka1bEKbxkmZWqvi9Ms0Q26jf52WPtM8+2h4MOtz4PQpGWPiAJiEZP0OU8yZPXzM2GbElQJYRjgBxFlbFN4Nzjrdxw27zkd1xdL65d/4m5X892VZsoBNyjwvT2u4+JkB8I+w009IqNBk5Afj8ZQIOMN4/EjubeiESt08XU2VGbyYXzJM5ZeUhnMbjwx6FnHaVzAFuSpp+8qVF/Tt0aVwuLlyCu9ijc+62WfVV3h+QHbrWPWEc6GulforHmz6blRa31Vm1W4JV19YjI0oxoNsuyoNh7lJ5suLWfuK9O2bf/7mdkAnZxwvrRkuwG1HLGabYx//8ju7jfZvUt+iJEGQ0qJEIIoirBtmzg2t54kVLKi61tKMZDvNY8/zK3bkuIwT23pomdKG8akRqftBf8calAX07qu/8lxnAlUZybPlkwnunzewR9yNLSB/tI4hQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"무효화\"\n        title=\"\"\n        src=\"/static/8b9cc074b2fc52b77cb43ed2bf2a5a30/f058b/inval.png\"\n        srcset=\"/static/8b9cc074b2fc52b77cb43ed2bf2a5a30/c26ae/inval.png 158w,\n/static/8b9cc074b2fc52b77cb43ed2bf2a5a30/6bdcf/inval.png 315w,\n/static/8b9cc074b2fc52b77cb43ed2bf2a5a30/f058b/inval.png 630w,\n/static/8b9cc074b2fc52b77cb43ed2bf2a5a30/40601/inval.png 945w,\n/static/8b9cc074b2fc52b77cb43ed2bf2a5a30/60b3a/inval.png 1179w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>이 방식의 장점은 데이터베이스의 신뢰할 수 있는 로그를 기반으로 하기 때문에, 무효화 명령이 손실되거나 잘못 전달되어도 로그를 재실행(replay)하여 복구할 수 있다는 것입니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/aadee91086a49f4321e70eda42e0169d/cc488/figure6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.0253164556962%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACV0lEQVR42m1S2W7iQBDk/38BCWm1EnlwpHBjErM4BkE4AhjbYG4IxwYI92kM1E4PIVGkbakZPDNdXVU9DuCCy+UCWm//b998vZ19rufzGafTiZ8djxYGgz7GoxHG4xEsy4LjcjmjWmtCK9dRqbWg6RXo5SrMehvVRgdG2URB1VGtd5BXDQz/vmO73WK/37O6Bh68IYTEKHz+EN/ngCY7oMtSLI6wKCGZyiKRysHrF6EbJlStAllJoViqwDRr6HY7aDabCIQiCD/GoOqMACN1Pp/guEoDj/1uh3argUI+g7gShSgGcXf3GwH/A7yeexQKr2i1WhzMMDQEg17cC3cQQ37YxyPHcNDPjtHfbDZ4Z3ICfgFyLID8q4Jn+QnSkw/hkACf181ASphOp/j4mCKXTeAlJSGT/gPl+ZH5aX8DDgYDKIqCdDqNbDbLmBS5R5Rk9Hq9gabpmEwmsO0T1qz5brfnIJZl871bcMDDwcJwOEQymUQmk0Gn00EsFmOSRUSjUcbiBbmkDMH9C1HRD72QYTWHz9fwMzggTader0NVVSbLYKZ3kUgk4PF4GGiESUuhZpZRKesw9BLP5XLJAW9P6Acgva31eo3ZbIbVasWl2rb9JXvHhkV3jsz4JTtfMDAC+l9wQDK6VCqh3+/jasGBNyBQKqSkRsSK1BA4sSIlun71loL2HFQkCAKcTifcbjd8Ph8fEHlHkmmNRCKQJAmyLPMkexaLBbfI5XIhHo9/A1K3t7ceHwR1NE0T7XabTVXjBcVikftKTCjpmwZIjOfzOb/X6/W+JP8DeU1nCfalkPEAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"무효화 파이프라인\"\n        title=\"\"\n        src=\"/static/aadee91086a49f4321e70eda42e0169d/f058b/figure6.png\"\n        srcset=\"/static/aadee91086a49f4321e70eda42e0169d/c26ae/figure6.png 158w,\n/static/aadee91086a49f4321e70eda42e0169d/6bdcf/figure6.png 315w,\n/static/aadee91086a49f4321e70eda42e0169d/f058b/figure6.png 630w,\n/static/aadee91086a49f4321e70eda42e0169d/cc488/figure6.png 928w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>실제로 대부분의 무효화는 데이터를 삭제하지 않습니다. 발행된 모든 DELETE 중 <strong>단 4%만</strong> 실제로 캐시된 데이터를 무효화합니다.</p>\n<h4>패킷 수 감소</h4>\n<p><strong>mcsqueal</strong>이 각 Memcached 서버에 직접 DELETE 명령을 보낼 수도 있지만, <strong>Storage Cluster</strong>에서 수많은 <strong>Frontend Cluster의 수천 대 Memcached 서버로 패킷</strong>을 직접 보내면 <strong>패킷 폭발</strong>(packet storm)이 발생합니다.</p>\n<p><strong>최적화 방법</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1. 무효화 데몬이 DELETE를 배치로 묶음\n2. 각 Frontend Cluster의 mcrouter 전용 서버로 전송\n3. mcrouter가 배치를 개별 DELETE로 언팩\n4. Frontend Cluster 내의 올바른 Memcached 서버로 라우팅</code></pre></div>\n<p>배치 처리 결과, 패킷당 DELETE 수의 중간값이 <strong>18배 개선</strong>되었습니다.</p>\n<h4>웹서버를 통한 무효화를 사용하지 않는 이유</h4>\n<p>웹서버가 모든 Frontend Cluster에 무효화를 브로드캐스트하는 방법이 더 간단하지만 두 가지 문제가 있습니다:</p>\n<ol>\n<li><strong>패킷 오버헤드</strong>: 웹서버는 mcsqueal 파이프라인보다 배치 처리가 덜 효과적</li>\n<li><strong>시스템적 문제 대응 어려움</strong>: 구성 오류로 인한 DELETE 잘못된 라우팅 발생 시, 과거에는 전체 Memcache 인프라를 롤링 재시작해야 했음 (느리고 방해적)</li>\n</ol>\n<p>반면, SQL 문에 무효화를 포함시키면 데이터베이스가 커밋하고 신뢰할 수 있는 로그에 저장하므로, mcsqueal은 손실되거나 잘못 라우팅된 무효화를 간단히 재생할 수 있습니다.</p>\n<h3>지역 풀 (Regional Pools)</h3>\n<p>각 클러스터는 전송되는 사용자 요청의 혼합에 따라 독립적으로 데이터를 캐시합니다. 사용자 요청이 모든 Frontend Cluster에 무작위로 라우팅되면, 캐시된 데이터는 모든 Frontend Cluster에서 대략 동일합니다.</p>\n<p>이를 통해 유지보수를 위해 클러스터를 오프라인으로 전환해도 히트율이 감소하지 않습니다. 하지만 데이터를 과도하게 복제하면 특히 크고 드물게 액세스되는 아이템의 경우 메모리 비효율적일 수 있습니다.</p>\n<h4>클러스터 vs 지역 복제 결정</h4>\n<p>여러 Frontend Cluster가 동일한 Memcached 서버 세트를 공유하도록 하여 복제본 수를 줄일 수 있습니다. 이를 <strong>Regional Pool</strong>이라고 합니다.</p>\n<ul>\n<li><strong>복제</strong>(단순 memcached 늘리기)</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c2d36b31b958437599f462997f53f6ee/ad1ae/cluster_repl.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.79746835443038%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAACKElEQVR42l2SW0/bQBCF+f8/qEUVUlupakOB5u5cHCcQSOK7vbZ3105Cvo4NDy0Px9odzzlzdmauEnMhN3RQ9g3tOZV4i/YeFRfi8i0ve49/zM8EUXXhKjKvvNiKR1OwqjI2uujOUX3iYA1PtmDoR0zimK0t8a0ltA1PpmRdKbwq7/JbjaAVPOgji/oZt5owSB6YqxEzu5AEzcqGLLTDNOszzQdyn+PZRIpmLK3bxYbCcStHOFv86pWrvT5L5SXYG2z8GaobYvODZ3HyqPfU9ivH9JpTds2x/s7GROIsQ9U9LuUX6vgTl+abFJlz0LQOT6zthkTfss970qtbnvQfcWiE7OPr3wQSbxGae8mNhZyzt0PpbY9DJhxzx8p44lAEA9Pg6BAna7j3FdO0pq8S9nXFUseMVUU/LBlEFVOl8UzCWqdMSsUotjwEhbSpYVwFBFqe7L8LuurMLDZ46pVh0QqWuCLoiKCbNh1mSv6bGE8nOGWBl5+ZC2dVnBiVvgiexaE8eWYOTMyOSbVjqLb0y8duKEshj5sDg2ovsRemRx/XtEMRd+VWCm87TsudSb+Ddihpu0fNhaxFLftmz4SFJd2FqL1MeTDFGzo4d31W47nEItKXgLBsSCQ3e+fmwg21rE3SCf6DkyxrVXNeurDZUA8G2Ntf2N5PmtEY1mtO8wVKRNTxf27Y7mEsn1h/QHkm3yWoXUzhy4rsog5ld467f7EM4CMvKC/8BRGCOiB0mCEeAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"클러스터 복제\"\n        title=\"\"\n        src=\"/static/c2d36b31b958437599f462997f53f6ee/f058b/cluster_repl.png\"\n        srcset=\"/static/c2d36b31b958437599f462997f53f6ee/c26ae/cluster_repl.png 158w,\n/static/c2d36b31b958437599f462997f53f6ee/6bdcf/cluster_repl.png 315w,\n/static/c2d36b31b958437599f462997f53f6ee/f058b/cluster_repl.png 630w,\n/static/c2d36b31b958437599f462997f53f6ee/40601/cluster_repl.png 945w,\n/static/c2d36b31b958437599f462997f53f6ee/78612/cluster_repl.png 1260w,\n/static/c2d36b31b958437599f462997f53f6ee/ad1ae/cluster_repl.png 2270w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li><strong>regional pool</strong></li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2cefe9b0203b378cae685c649dcd73de/50517/share.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 79.11392405063292%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAABYlAAAWJQFJUiTwAAACWklEQVR42pVU23KbMBDN//9Lm8e2M+lMnpy2k3ET3wDXsU1MbHORkARCgLFPVjjxJA556MNhxdHu0bK74oIXB7BO4IS12GMj9++4c/+EwPUBF3ZTVB0wBtJo5LXBVmSIVd6upckJpjMmsYLcdInV2Oke9sUVZPAV2foScvUFIrjEwfzELu9BlB/jbKafCO5Q6z4KcY1o9R1sc4Vw9QMb/xuMvEad95H+lyBB1cAsiBGwDOs0gx+lZHP8C6J2ryvmU8G0PFBwQQ47qAaI9Q5bWSJrbJ12tGdreICoD0itPReU1QtqK0YdFYY2mxPPaR1n5cmHkejGitLBNlt5LsjKBqxqsFEGj0wi1BWdTLwhng7YkphPPKv27bvNKiIfP5FtzJFv2nG6SPQeMxNhqB/Rixz8YVOMyhWeaDyWJsWA+F+JS/AwKlbwjcBSC4xNgN/E3cQOhsTPTHwcm1g38EjQUQVG1ACPPnegGAKj8FBwjJXEmOeYEJwsw8JwzDTDJBNwuG75aUZWh8dPjqk+bhHBpUIMogwuI6tSBKXCrGAYSxJKDCYWUpMgawWtuJOUGIbU+azCKH8RtI8FZeLkEbw8xijdYCACrLTGXFN2RYJ7scUdX8MlsQVxy1xhKNatr5cnbexCp8ca2qao6ojXrqbURRFsoZ9CzG7v4feHmN7cYt4fQa8juj0hdX5/8n+N7Z5DO7Sart58Afg+GtdFffeX0EfjeS1XP8zbkekcbJumvUZvwQ05xxIy5FCJIMugTmsOQePCy49xcftzePdLeoPyiMR0r8/9k8JeAOAZGH3D3teVo3EAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"지역풀\"\n        title=\"\"\n        src=\"/static/2cefe9b0203b378cae685c649dcd73de/f058b/share.png\"\n        srcset=\"/static/2cefe9b0203b378cae685c649dcd73de/c26ae/share.png 158w,\n/static/2cefe9b0203b378cae685c649dcd73de/6bdcf/share.png 315w,\n/static/2cefe9b0203b378cae685c649dcd73de/f058b/share.png 630w,\n/static/2cefe9b0203b378cae685c649dcd73de/40601/share.png 945w,\n/static/2cefe9b0203b378cae685c649dcd73de/78612/share.png 1260w,\n/static/2cefe9b0203b378cae685c649dcd73de/50517/share.png 2060w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><strong>트레이드오프</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">복제 (Cluster별 Pool):\n+ 낮은 지연시간\n+ 높은 가용 대역폭 (클러스터 내부)\n+ 더 나은 장애 내성\n- 더 많은 Memcached 서버 필요\n\n지역화 (Regional Pool):\n+ 메모리 효율적\n+ 적은 서버 필요\n- 더 높은 지연시간 (클러스터 간)\n- 40% 낮은 가용 대역폭</code></pre></div>\n<p><strong>네트워크 토폴로지 차이</strong></p>\n<p><strong>클러스터 내부 통신:</strong></p>\n<ul>\n<li>같은 데이터센터, 같은 랙에 위치</li>\n<li>물리적 거리가 가깝고 네트워크 홉이 적음</li>\n<li>높은 대역폭 사용 가능 (예: 10Gbps, 40Gbps 전용)</li>\n<li>빠르고 병목이 적음</li>\n</ul>\n<p><strong>클러스터 경계 넘는 통신:</strong></p>\n<ul>\n<li>다른 랙 또는 다른 데이터센터 간 통신</li>\n<li>여러 스위치를 거쳐야 함 (ToR → Aggregation → Core → Aggregation → ToR)</li>\n<li>물리적 거리가 멀고 네트워크 홉이 많음</li>\n<li>상위 스위치의 대역폭을 여러 클러스터가 공유</li>\n<li>느리고 동시 다량 전송 시 병목 발생</li>\n</ul>\n<p>이러한 이유로 Regional Pool은 메모리는 절약되지만, 네트워크 성능이 저하됩니다.</p>\n<p><strong>실제 사례</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">카테고리 A (Cluster별 복제):\n- 중간 사용자 수: 30명\n- 초당 GET 수: 3.26M\n- 중간 값 크기: 10.7 kB\n\n카테고리 B (Regional Pool):\n- 중간 사용자 수: 1명\n- 초당 GET 수: 458K\n- 중간 값 크기: 4.34 kB</code></pre></div>\n<p><strong>카테고리 B의 Regional Pool 적합성:</strong></p>\n<p>카테고리 B는 액세스 빈도가 낮아 Regional Pool의 주요 후보입니다:</p>\n<ul>\n<li>클러스터 간 대역폭에 부정적인 영향을 주지 않음 (요청이 적음)</li>\n<li>각 클러스터의 Wildcard Pool(한 클러스터의 Memcached 풀)의 <strong>25%를 차지</strong></li>\n</ul>\n<p><strong>메모리 절약 효과:</strong></p>\n<p>예를 들어, 클러스터가 4개 있다면:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">복제 방식 (변경 전):\n- 각 클러스터가 카테고리 B 데이터를 독립적으로 저장\n- 같은 데이터가 4번 중복 저장됨\n- Wildcard Pool의 25% × 4개 클러스터 = 전체 메모리의 큰 비중\n\nRegional Pool 방식 (변경 후):\n- 카테고리 B 데이터를 Region 전체에서 한 번만 저장\n- 각 클러스터의 Wildcard Pool에서 25% 메모리 확보\n- 전체 Memcached 메모리 사용량 대폭 감소</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/13dde18cedab5e8ada71fc1a03cdd999/84a90/table1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 27.21518987341772%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAAA7ElEQVR42o1Qa2+DMBDj//85oO2AUA0GKyWBBCpGuvJIvOTQ9nknnfKQzz47wD9rnr+glKKepgnLskBKib7voNyptSZcsO8buGhxvzcYlITsewgh3KBE1wlqrWd0guN6zRHHEW63TzweI+qqQpq8IUsTcN4ehMYYsCzD+RQjZ4zucRTioywJVJYFXq9vAgtH6v+N2d3LYt82wnhyX9YaBNYR5jlD4pVYiqJ4R+oUm6ZxI/bP8vOpCReFIdn0NY4DLpezW+aEdV2ODb2SlB3quiKbvG3Jplc+NrPU67oeGbq8fJ6+fBTDoCiuX8IfGrl6j0yzpEIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"클러스터 vs 지역 복제 결정 요인\"\n        title=\"\"\n        src=\"/static/13dde18cedab5e8ada71fc1a03cdd999/f058b/table1.png\"\n        srcset=\"/static/13dde18cedab5e8ada71fc1a03cdd999/c26ae/table1.png 158w,\n/static/13dde18cedab5e8ada71fc1a03cdd999/6bdcf/table1.png 315w,\n/static/13dde18cedab5e8ada71fc1a03cdd999/f058b/table1.png 630w,\n/static/13dde18cedab5e8ada71fc1a03cdd999/40601/table1.png 945w,\n/static/13dde18cedab5e8ada71fc1a03cdd999/84a90/table1.png 982w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><strong>의사결정 방식:</strong></p>\n<p>현재 Regional Pool로 데이터를 마이그레이션하는 결정은 <strong>수동 휴리스틱</strong>에 기반합니다:</p>\n<ul>\n<li><strong>액세스 속도</strong>: 얼마나 자주 요청되는가?</li>\n<li><strong>데이터 세트 크기</strong>: 데이터가 얼마나 큰가?</li>\n<li><strong>고유 사용자 수</strong>: 몇 명의 사용자가 접근하는가?</li>\n</ul>\n<p>자동화된 알고리즘이 아닌, 실제 운영 경험과 이러한 기준들을 보고 <strong>운영자가 직접 판단</strong>하여 결정합니다. 예를 들어, 크고 드물게 접근되며 소수의 사용자만 사용하는 데이터는 Regional Pool에 넣는 것이 효율적입니다.</p>\n<h3>콜드 클러스터 워밍업</h3>\n<p>새 클러스터를 배포하거나, 기존 클러스터가 장애로 재시작되거나, 예정된 유지보수를 수행할 때 캐시는 매우 낮은 히트율을 가지게 되어 백엔드 서비스를 보호하는 능력이 감소합니다.</p>\n<h4>Cold Cluster Warmup 시스템</h4>\n<p><strong>Cold Cluster</strong>(캐시가 비어있는 Frontend Cluster)의 클라이언트가 <strong>DB</strong>가 아닌 <strong>Warm Cluster</strong>(정상 히트율을 가진 클러스터)에서 데이터를 검색할 수 있도록 합니다.</p>\n<p>이 시스템을 통해 Cold Cluster는 며칠이 아닌 <strong>몇 시간 만에</strong> 전체 용량으로 복구될 수 있습니다.</p>\n<h4>Race Condition 방지</h4>\n<p>Cold Cluster Warmup 과정에서 <strong>Region 간 DB 복제 지연</strong>으로 인한 stale data 문제가 발생할 수 있습니다.</p>\n<p><strong>전제 조건:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">미국 Region:\n- Cold Cluster (캐시 비어있음)\n- Storage Cluster (MySQL)\n\n유럽 Region:\n- Warm Cluster (정상 캐시)\n- Storage Cluster (MySQL)\n\n중요: 미국 MySQL ↔ 유럽 MySQL은 비동기 복제 (수초~수분 지연)</code></pre></div>\n<p><strong>문제 시나리오:</strong></p>\n<p>사용자 A가 미국에서 프로필 사진을 \"old.jpg\"에서 \"new.jpg\"로 변경하는 상황</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[시간 0ms] 미국에서 프로필 사진 변경\n- 사용자 A: 미국 MySQL에 업데이트 (user:1 = \"new.jpg\")\n- 미국 mcsqueal: DELETE 명령을 전세계 모든 캐시에 브로드캐스트\n\n[시간 50ms] 캐시 무효화 완료 (빠름!)\n- 미국 Cold Cluster 캐시: 삭제됨 ✓\n- 유럽 Warm Cluster 캐시: 삭제됨 ✓\n\n[시간 100ms] 사용자 B가 미국 Cold Cluster에서 프로필 사진 조회\n1. 미국 Cold Cluster 캐시 조회 → 미스 (이미 삭제됨)\n2. Cold Cluster Warmup 로직 발동\n   → Warm Cluster(유럽)에서 데이터 가져오기 시도\n3. 유럽 Warm Cluster 캐시 조회 → 미스 (이미 삭제됨)\n4. 유럽 MySQL 조회\n   → 문제: 아직 미국→유럽 MySQL 복제가 안됨!\n   → 유럽 MySQL에는 여전히 \"old.jpg\"\n5. \"old.jpg\"를 미국 Cold Cluster 캐시에 저장\n\n[시간 3초] MySQL 복제 완료 (느림!)\n- 유럽 MySQL: \"new.jpg\"로 업데이트됨\n- 하지만 미국 Cold Cluster 캐시에는 여전히 \"old.jpg\" (stale data!)</code></pre></div>\n<p><strong>핵심 문제:</strong></p>\n<ul>\n<li><strong>캐시 무효화는 빠름</strong> (밀리초 단위로 전세계 전파)</li>\n<li><strong>MySQL 복제는 느림</strong> (수초~수분 소요)</li>\n<li>이 시간 차이 때문에 Warm Cluster에서 옛날 데이터를 가져와 Cold Cluster에 저장하는 문제 발생</li>\n</ul>\n<h4>Hold-off 메커니즘: Race Condition 해결</h4>\n<p>위에서 설명한 Race Condition 문제를 해결하기 위해 <strong>Hold-off 메커니즘</strong>을 사용합니다.</p>\n<p><strong>해결 원리:</strong></p>\n<p>Memcached DELETE 명령은 <strong>Hold-off 시간</strong>을 지정할 수 있습니다. Hold-off 시간 동안 해당 키에 대한 <strong>ADD 연산을 거부</strong>합니다.</p>\n<p><strong>동작 방식:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token comment\">// 1. Cold Cluster의 모든 DELETE는 2초 hold-off로 발행</span>\nmemcache<span class=\"token punctuation\">.</span><span class=\"token function\">delete</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">,</span> holdOffSeconds <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// 2. Cold Cluster에서 미스 감지 시</span>\nvalue <span class=\"token operator\">=</span> coldCluster<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>value <span class=\"token operator\">==</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// 3. Warm Cluster에서 재요청</span>\n    value <span class=\"token operator\">=</span> warmCluster<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">// 4. Cold Cluster에 ADD 시도</span>\n    <span class=\"token keyword\">boolean</span> success <span class=\"token operator\">=</span> coldCluster<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>success<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token comment\">// ADD 실패 = hold-off 중 = 더 최신 데이터 존재</span>\n        <span class=\"token comment\">// 5. DB에서 다시 조회</span>\n        value <span class=\"token operator\">=</span> database<span class=\"token punctuation\">.</span><span class=\"token function\">select</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p><strong>Race Condition 방지 과정:</strong></p>\n<ol>\n<li><strong>[0ms]</strong> 미국에서 프로필 사진 변경 (user:1 = \"new.jpg\")</li>\n<li><strong>[50ms]</strong> mcsqueal이 DELETE 명령 브로드캐스트 (2초 hold-off 포함)\n<ul>\n<li>미국 Cold Cluster 캐시 삭제 + 2초간 ADD 금지</li>\n</ul>\n</li>\n<li><strong>[100ms]</strong> 사용자 B가 미국 Cold Cluster에서 조회\n<ul>\n<li>Cold Cluster 미스 → Warm Cluster(유럽) 조회</li>\n<li>유럽 캐시 미스 → 유럽 MySQL 조회 (아직 \"old.jpg\")</li>\n<li>Cold Cluster에 ADD 시도 → <strong>실패</strong> (hold-off 중!)</li>\n<li>DB(미국 MySQL) 직접 조회 → \"new.jpg\" 획득</li>\n</ul>\n</li>\n<li><strong>[3초]</strong> MySQL 복제 완료 (유럽 MySQL도 \"new.jpg\")</li>\n</ol>\n<p><strong>결과:</strong> Hold-off 덕분에 stale 데이터(\"old.jpg\")가 캐시에 저장되지 않고, 최신 데이터(\"new.jpg\")를 DB에서 직접 가져옵니다.</p>\n<p><strong>트레이드오프:</strong></p>\n<p>DELETE가 2초 이상 지연될 이론적 가능성은 있지만, 대다수의 경우에는 해당되지 않습니다. Cold Cluster Warmup의 운영상 이점이 드문 캐시 일관성 문제의 비용보다 훨씬 큽니다. Cold Cluster의 히트율이 안정화되고 이점이 감소하면 이 기능을 끕니다.</p>\n<h2>지역 간 확장: 일관성</h2>\n<h3>지리적 분산의 이점</h3>\n<p>데이터 센터를 더 넓은 지리적 영역에 배치하면 여러 이점이 있습니다:</p>\n<ol>\n<li><strong>지연시간 감소</strong>: 웹서버를 최종 사용자에게 가까이 배치</li>\n<li><strong>지리적 다양성</strong>: 자연재해나 대규모 정전 같은 이벤트의 영향 완화</li>\n<li><strong>경제적 인센티브</strong>: 더 저렴한 전력 및 기타 경제적 혜택</li>\n</ol>\n<p>Facebook은 여러 Region에 배포하여 이러한 이점을 얻습니다. 각 Region은 Storage Cluster와 여러 Frontend Cluster로 구성됩니다.</p>\n<h3>마스터-복제본 아키텍처</h3>\n<p>하나의 Region을 마스터 데이터베이스를 보유하도록 지정하고, 다른 Region은 읽기 전용 복제본을 포함하도록 합니다. MySQL의 복제 메커니즘을 사용하여 복제 데이터베이스를 마스터와 최신 상태로 유지합니다.</p>\n<p>이 설계에서 웹서버는 로컬 Memcached 서버나 로컬 데이터베이스 복제본에 액세스할 때 낮은 지연시간을 경험합니다.</p>\n<p><strong>주요 기술적 과제</strong></p>\n<p>여러 Region에 걸쳐 확장할 때, Memcache의 데이터와 DB 간의 <strong>일관성 유지</strong>가 주요 기술적 과제가 됩니다. 이러한 문제는 <strong>복제 데이터베이스가 마스터 데이터베이스보다 뒤처질 수 있다</strong>는 단일 문제에서 비롯됩니다.</p>\n<h3>일관성 모델의 철학</h3>\n<p>Facebook의 시스템은 일관성과 성능 트레이드오프 스펙트럼의 한 지점을 나타냅니다. 일관성 모델은 사이트의 규모에 맞게 수년에 걸쳐 진화했습니다.</p>\n<p>시스템이 관리하는 대량의 데이터는 네트워크나 스토리지 요구사항을 증가시키는 사소한 변경도 막대한 비용이 든다는 것을 의미합니다. 더 엄격한 의미론을 제공하는 대부분의 아이디어는 비용이 너무 비싸서 설계 단계를 거의 벗어나지 못합니다.</p>\n<p><strong>설계 목표</strong></p>\n<ol>\n<li>사용자 대면 또는 운영 문제에 영향을 미치는 변경만 수행</li>\n<li><strong>일시적으로 stale한 데이터를 읽을 확률</strong>을 조정 가능한 매개변수로 취급 (응답성과 유사)</li>\n<li>백엔드 스토리지 서비스를 과도한 부하로부터 보호하기 위해 약간 stale한 데이터 노출 허용</li>\n</ol>\n<p>Facebook은 <strong>Best-effort Eventual Consistency</strong>를 제공하지만 성능과 가용성을 강조합니다.</p>\n<h3>마스터 Region에서의 쓰기 처리</h3>\n<p>Storage Cluster가 데몬을 통해 데이터를 무효화하도록 요구하는 초기 결정은 다중 Region 아키텍처에서 중요한 결과를 가져옵니다.</p>\n<p><strong>Race Condition 방지</strong></p>\n<p>무효화가 데이터가 마스터 Region에서 복제되기 전에 도착하는 Race Condition을 피합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">문제가 되는 시나리오 (웹서버가 직접 무효화):\n1. 마스터 Region 웹서버: DB 수정 완료\n2. 웹서버: 복제본 Region에 무효화 전송\n3. 복제본 Region: 캐시에서 데이터 삭제\n4. 복제본 Region 클라이언트: 데이터 조회 (캐시 미스)\n5. 복제본 DB 조회 → 아직 복제 안됨 (stale 데이터)\n6. Stale 데이터를 캐시에 저장\n\n안전한 방법 (mcsqueal 사용):\n1. 마스터 Region 웹서버: DB 수정 + 무효화 키 포함\n2. 마스터 DB: 트랜잭션 커밋 + 로그 기록\n3. 복제 스트림: 복제본 Region으로 전파\n4. 복제본 DB: 데이터 업데이트\n5. mcsqueal: 복제 스트림에서 무효화 추출\n6. mcsqueal: 복제본 Region Memcache 무효화</code></pre></div>\n<p><strong>Lease로 Race Condition 방지:</strong></p>\n<p>문제가 되는 시나리오의 4-6단계에서 발생할 수 있는 Race Condition은 <strong>Lease 메커니즘</strong>으로 해결됩니다:</p>\n<ol>\n<li><strong>[단계 4]</strong> 복제본 Region 클라이언트가 캐시 미스 시 <strong>lease 발급</strong></li>\n<li>복제본 DB에서 stale 데이터 조회</li>\n<li><strong>[단계 2 이후]</strong> mcsqueal의 DELETE 명령이 도착하면 <strong>해당 키의 모든 outstanding lease 무효화</strong></li>\n<li><strong>[단계 6]</strong> 클라이언트가 stale 데이터를 ADD/SET 시도\n<ul>\n<li>Lease가 무효화되어 있으면 <strong>실패</strong></li>\n<li>실패 시 다시 DB 조회 (이때는 복제 완료되어 최신 데이터)</li>\n</ul>\n</li>\n</ol>\n<p>이를 통해 복제 타이밍과 무관하게 stale 데이터가 캐시에 저장되는 것을 방지합니다.</p>\n<p><strong>mcsqueal을 사용하는 이유:</strong></p>\n<p>Lease만으로도 stale 데이터 캐싱을 방지할 수 있지만, mcsqueal을 사용하는 이유는:</p>\n<ol>\n<li><strong>순서 보장</strong>: MySQL 복제 스트림에서 무효화를 추출하므로 DB 업데이트 후 무효화 순서 보장</li>\n<li><strong>웹서버 부하 감소</strong>: 여러 Region에 무효화 요청을 보내는 오버헤드 제거</li>\n<li><strong>안정적인 전파</strong>: 복제 스트림 기반이므로 네트워크 일시 장애에도 결국 무효화 전파 보장</li>\n</ol>\n<p>Lease는 최후의 방어선, mcsqueal은 설계상 안전성을 제공합니다.</p>\n<h3>비마스터 Region에서의 쓰기 처리</h3>\n<p><strong>문제 시나리오:</strong></p>\n<p>사용자가 유럽 Region(비마스터)에서 프로필 사진을 \"old.jpg\" → \"new.jpg\"로 변경:</p>\n<ol>\n<li><strong>[0ms]</strong> 유럽 웹서버가 미국 마스터 DB에 쓰기 (user:1 = \"new.jpg\")</li>\n<li><strong>[100ms]</strong> 미국 마스터 DB 업데이트 완료 (user:1 = \"new.jpg\")</li>\n<li><strong>[200ms]</strong> 사용자가 페이지 새로고침 (유럽에서 조회)\n<ul>\n<li>유럽 캐시 미스 → 유럽 DB 조회</li>\n<li>문제: 미국→유럽 MySQL 복제가 아직 안 됨 (수초 소요)</li>\n<li>유럽 DB에는 여전히 \"old.jpg\" → 캐시에 \"old.jpg\" 저장</li>\n</ul>\n</li>\n<li><strong>[3초]</strong> MySQL 복제 완료 (유럽 DB도 \"new.jpg\"), 하지만 캐시에는 \"old.jpg\" (stale 데이터)</li>\n</ol>\n<p><strong>핵심 문제:</strong> 비마스터 Region에서 업데이트 후 즉시 조회하면, 로컬 DB 복제가 완료되기 전에 stale 데이터를 캐싱할 수 있습니다.</p>\n<h4>Remote Marker 메커니즘</h4>\n<p>위 문제를 해결하기 위해 <strong>Remote Marker</strong>를 사용합니다. 핵심 아이디어는 <strong>\"이 데이터를 방금 수정했다\"는 표시를 남겨두는 것</strong>입니다.</p>\n<p><strong>동작 원리 (구체적 예시):</strong></p>\n<p>유럽에서 프로필 사진을 \"old.jpg\" → \"new.jpg\"로 변경하는 경우:</p>\n<p><strong>[쓰기 시]</strong></p>\n<ol>\n<li><strong>Regional Pool에 marker 설정</strong>: <code class=\"language-text\">r:user:1 = \"1\"</code> (유럽 Region 전체에서 공유)\n<ul>\n<li>\"user:1을 방금 수정했다\"는 표시</li>\n</ul>\n</li>\n<li><strong>미국 마스터 DB 업데이트</strong>: <code class=\"language-text\">user:1 = \"new.jpg\"</code>\n<ul>\n<li>무효화 키에 <code class=\"language-text\">user:1</code>과 <code class=\"language-text\">r:user:1</code> 포함 (mcsqueal이 나중에 처리)</li>\n</ul>\n</li>\n<li><strong>유럽 로컬 캐시 삭제</strong>: <code class=\"language-text\">user:1</code> 삭제</li>\n</ol>\n<p><strong>[200ms 후 조회 시]</strong></p>\n<ol>\n<li>유럽 로컬 캐시 조회 → 미스 (방금 삭제했으므로)</li>\n<li><strong>Regional Pool에서 marker 확인</strong>: <code class=\"language-text\">r:user:1</code> 존재하는가?\n<ul>\n<li><strong>존재함</strong> → \"아, 방금 수정된 데이터구나. 로컬 DB는 아직 복제 안 됐을 수 있음\"</li>\n<li><strong>미국 마스터 Region에 직접 쿼리</strong> → \"new.jpg\" 획득 (정확한 데이터!)</li>\n</ul>\n</li>\n<li>Marker가 없었다면 → 유럽 로컬 DB 조회 (stale 위험)</li>\n</ol>\n<p><strong>[3초 후 - 복제 완료 시]</strong></p>\n<ul>\n<li>mcsqueal이 <code class=\"language-text\">r:user:1</code> marker 무효화</li>\n<li>이후 조회는 유럽 로컬 DB에서 안전하게 조회 가능 (복제 완료되었으므로)</li>\n</ul>\n<p><strong>핵심:</strong> Remote Marker는 <code class=\"language-text\">\"복제가 완료될 때까지 마스터에 직접 물어보라\"</code>는 임시 신호등 역할을 합니다.</p>\n<p><strong>트레이드오프:</strong></p>\n<p>캐시 미스 시 마스터 Region 쿼리로 인한 추가 지연시간 발생, 하지만 stale 데이터 방지.</p>\n<h3>운영상 고려사항</h3>\n<p>지역 간 통신은 데이터가 큰 지리적 거리(예: 미국 대륙 횡단)를 이동해야 하므로 비용이 많이 듭니다.</p>\n<p><strong>네트워크 효율성:</strong></p>\n<p>DELETE 스트림을 데이터베이스 복제와 동일한 통신 채널로 공유함으로써 낮은 대역폭 연결에서 네트워크 효율성을 얻습니다.</p>\n<p><strong>mcsqueal 배포 위치:</strong></p>\n<p>mcsqueal은 각 Region의 복제 DB와 함께 배포됩니다.</p>\n<p><strong>동작 방식:</strong></p>\n<ul>\n<li>미국 마스터 DB에서 <code class=\"language-text\">UPDATE user:1 = \"new.jpg\"</code> 실행</li>\n<li>MySQL은 이 변경사항을 <strong>바이너리 로그</strong>(transaction log)에 기록</li>\n<li>유럽 MySQL 복제본이 이 바이너리 로그를 받아서 자신의 DB에 반영</li>\n<li><strong>유럽의 mcsqueal</strong>이 유럽 MySQL 바이너리 로그를 읽음</li>\n<li>무효화 키(<code class=\"language-text\">user:1</code>) 추출 → 유럽 Memcache에 DELETE 전송</li>\n</ul>\n<p>즉, mcsqueal은 로컬 DB의 변경 로그를 읽어서 로컬 캐시를 무효화합니다.</p>\n<p><strong>장애 시 버퍼링 메커니즘:</strong></p>\n<p>Memcache 서버나 네트워크에 일시적 장애가 발생하면:</p>\n<p><strong>문제 상황:</strong></p>\n<ul>\n<li>mcsqueal이 Memcache에 DELETE를 보내려 했지만 Memcache 서버가 다운됨</li>\n<li>DELETE가 전달되지 않음 → 캐시가 무효화되지 않음</li>\n<li>이후 조회 시 stale 데이터를 읽을 위험 증가</li>\n</ul>\n<p><strong>해결 방법:</strong></p>\n<ul>\n<li>mcrouter와 DB가 DELETE 명령을 <strong>메모리에 버퍼링</strong>(임시 저장)</li>\n<li>Memcache 서버가 복구되면 <strong>버퍼링된 DELETE를 모두 재전송</strong></li>\n<li>결국 캐시 무효화 보장</li>\n</ul>\n<p><strong>다른 접근법과 비교:</strong></p>\n<ol>\n<li><strong>클러스터 오프라인 전환</strong>: 장애 감지 시 클러스터 전체를 중단 → 서비스 중단으로 인한 손실이 더 큼</li>\n<li><strong>과도한 무효화</strong>: 모든 캐시를 다 삭제 → DB 부하 폭증</li>\n</ol>\n<p>Facebook은 일시적인 stale 데이터 노출을 허용하되, 버퍼링으로 결국 일관성을 보장하는 방식을 선택했습니다.</p>\n<h2>단일 서버 성능 개선</h2>\n<p>All-to-All 통신 패턴은 단일 서버가 클러스터의 병목이 될 수 있음을 의미합니다. 이 섹션에서는 Memcached의 성능 최적화와 메모리 효율성 향상을 설명합니다. 클러스터 내에서 더 나은 확장을 가능하게 합니다.</p>\n<h3>성능 최적화</h3>\n<p>Facebook은 고정 크기 해시 테이블을 사용하는 단일 스레드 Memcached로 시작했습니다.</p>\n<p><strong>초기 주요 최적화</strong></p>\n<ol>\n<li><strong>해시 테이블 자동 확장</strong>: 조회 시간이 O(n)으로 늘어나는 것 방지</li>\n<li><strong>멀티스레드 지원</strong>: 글로벌 락으로 여러 데이터 구조 보호</li>\n<li><strong>스레드별 UDP 포트</strong>: 응답 전송 시 경합 감소 및 인터럽트 처리 오버헤드 분산</li>\n</ol>\n<p>처음 두 최적화는 오픈소스 커뮤니티에 기여되었습니다.</p>\n<h4>Fine-grained Locking</h4>\n<p><strong>문제:</strong> 기존 Memcached는 전체 해시 테이블에 <strong>하나의 락</strong>(Global Lock)을 사용했습니다.</p>\n<ul>\n<li>여러 스레드가 서로 다른 키에 접근해도 같은 락을 놓고 경쟁</li>\n<li>멀티코어 환경에서 병목 발생</li>\n</ul>\n<p><strong>해결:</strong> 해시 테이블을 여러 파티션으로 나누고 <strong>각 파티션마다 독립적인 락</strong> 부여</p>\n<ul>\n<li>스레드 A가 <code class=\"language-text\">user:1</code> 접근, 스레드 B가 <code class=\"language-text\">user:2</code> 접근 시 서로 다른 락 사용 가능</li>\n<li>락 경합 감소 → 병렬성 향상</li>\n</ul>\n<p><strong>성능 테스트 결과</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">테스트 환경:\n- Intel Xeon CPU (X5650) @ 2.67GHz\n- 12코어 + 12 하이퍼스레드\n- Intel 82574L 기가비트 이더넷\n- 12GB 메모리\n- 15개 클라이언트 → 1개 서버 (24 스레드)\n\n10-key Multiget 성능 (1ms 이하 평균 응답 시간):\n\n히트:\n- 원래 멀티스레드: 600K items/초\n- Fine-grained locking: 1.8M items/초 (3배 향상)\n\n미스:\n- 원래 멀티스레드: 2.7M items/초\n- Fine-grained locking: 4.5M items/초</code></pre></div>\n<p><strong>왜 캐시 히트가 미스보다 느린가?</strong></p>\n<p>Multiget 요청: <code class=\"language-text\">GET user:1, user:2, user:3</code></p>\n<p><strong>히트 (600K items/초):</strong></p>\n<ul>\n<li>각 키의 값을 메모리에서 읽기</li>\n<li>각 값을 응답 패킷으로 구성</li>\n<li>네트워크로 전송</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">VALUE user:1 \"profile_data_1\"\nVALUE user:2 \"profile_data_2\"\nVALUE user:3 \"profile_data_3\"\nEND</code></pre></div>\n<p><strong>미스 (2.7M items/초):</strong></p>\n<ul>\n<li>해시 테이블 조회만 하고 값이 없음을 확인</li>\n<li>간단한 응답 하나만 전송</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">END</code></pre></div>\n<p>히트는 실제 데이터를 읽고 전송해야 하므로 더 많은 작업이 필요합니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0e2626eff41c0053a6c4cda1114c9eae/cc488/figure7.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.9620253164557%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAACAklEQVR42pVTTW/TQBDNz+JvwA/okXtVFTU9RIILCKlCqkRBKiCFUw+olXoEtYIWKakrtQXXcRM1dmI7tuM4id04/oqdx+46cRIkDqz17PXszpuZt7MFYAqK6TQloPNsZPP/R4ES0WFZXbTbLYRhwJAkE0wmMcMsxMrzT8J5dnEcEYRoNNv4LdQhigIcx4Hv+zPCdOaEFYKssgw5Yb1+B0G4hec9QO3oUDQDtZpASEX4gZ+TRHGM0dgn2Sd/ZYbVDDnuAtVqBYNBH647RByFSNIJWSKOJHKSJszlhLtHaf8MUsfOSfwggNEbIIwiZinQF8/zUFWFGTzPY19Js1G9VTD2gzyLb5yErfc/0VTt/PCqvIJne2cQ5e6ccIqbm2ucnp5A01RCkJV4+F3E5rtzGNaQ2S6uBJSPOZQ+VghhLyes8Co2984XhFRMmp1t20zYh9GImBMc/bjD9n4FfcdDrdHCoydFrG2X8bx8SUrus33rLz5g680himSf0DQXGdIREC2CYIxrvo7Szme8/vQVb49+wR6OICk61jZ2USTOu1+uoPdc9AcOHj99ifVXB9g5uES9tVTyom0iJnLjXobcVmBaFutD1qOKAt0wYHYtWD0LKTkoqrdpmrBIdely2ywfP70hht6BLEtks465JC3yr3c0orPCLgANlKYpC+a6Tt6rfwBZYDNiD5jkwQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Memcached 버전별 성능 비교\"\n        title=\"\"\n        src=\"/static/0e2626eff41c0053a6c4cda1114c9eae/f058b/figure7.png\"\n        srcset=\"/static/0e2626eff41c0053a6c4cda1114c9eae/c26ae/figure7.png 158w,\n/static/0e2626eff41c0053a6c4cda1114c9eae/6bdcf/figure7.png 315w,\n/static/0e2626eff41c0053a6c4cda1114c9eae/f058b/figure7.png 630w,\n/static/0e2626eff41c0053a6c4cda1114c9eae/cc488/figure7.png 928w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4>UDP vs TCP 성능</h4>\n<p>UDP 구현이 TCP 구현보다 성능이 우수합니다:</p>\n<ul>\n<li><strong>Single GET</strong>: 13% 향상</li>\n<li><strong>10-key Multiget</strong>: 8% 향상</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1930e6ecbbf86f89215cff09ad855e77/c6bbc/figure8.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.26582278481012%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACB0lEQVR42nWSz2/SYBjH+Zu8eXE3L5rdTMw8ePDHwUQXj3rY0MlAZmJiYjxo2JwjsigZspmQTY2MyIDFihiBbgYXxuhWuvUno4W2X9+3XcEt+iRP8rZP+3me5/t+fbZtwbJM6HoHtm0DoOmF/Z/8V7g1Hz1SYLlchiSJECUZnc6hc+71uifAgG4YkBQViqqhWN1GmvmN7PctaO2OU/fJsoRqtQLTNB1IoVhBlWWRy62Rd70+0CRNaSykvmD4eggjo49wK7wA/0sG/kgWXEt0gTs7DaRSKWcqUdzHdnMP9XodtVoNhqE7MCqLB4wmPuP0hXGcvTyBm+EEwvM/EIyuY1eQXKAgtJDP57CxwToT0vWpll564QFjyTTOjNzDuSsBMmECoVgJwbnCANhq8chkVtHtGtA0lQAtd0kCM4heuq6TWncAXFzF0KX7OH91EqNTCTycLyEU/QvI8zwYhnE0bGsKnswkcWPsOW4/iCAwncbk3Dpm3hedhjRm459wavgOhi6O4drEW/hnv2E8khto6Gkkigc4bKuYfvMBd6eiCD6LI7ZSwuuPFSznN0lD98azX38i8DSOxy/e4dVSAUtrW0hmWIiydhxILeLpR+NgX0CL3z1a3+pbh575PQ7NRh1cs4Ffm6zz7H3nO2la72dVVYjXlCPTHK+rqgpBECArMjiOI5cp9e31B51p0aS+VASUAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"GET 성능: TCP vs UDP\"\n        title=\"\"\n        src=\"/static/1930e6ecbbf86f89215cff09ad855e77/f058b/figure8.png\"\n        srcset=\"/static/1930e6ecbbf86f89215cff09ad855e77/c26ae/figure8.png 158w,\n/static/1930e6ecbbf86f89215cff09ad855e77/6bdcf/figure8.png 315w,\n/static/1930e6ecbbf86f89215cff09ad855e77/f058b/figure8.png 630w,\n/static/1930e6ecbbf86f89215cff09ad855e77/c6bbc/figure8.png 910w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4>Multiget vs Single GET</h4>\n<p>Multiget은 각 요청에 더 많은 데이터를 포함하므로 동일한 작업에 더 적은 패킷을 사용합니다:</p>\n<ul>\n<li><strong>10-key Multiget</strong>: Single GET 대비 약 <strong>4배 향상</strong></li>\n</ul>\n<h3>적응형 슬랩 할당자 (Adaptive Slab Allocator)</h3>\n<p>Memcached는 메모리를 관리하기 위해 <strong>Slab Allocator</strong>를 사용합니다.</p>\n<h4>기본 Slab Allocator</h4>\n<p><strong>비유: 크기별로 나눠진 주차장</strong></p>\n<p>Memcached는 메모리를 <strong>크기별로 미리 나눠진 주차 공간</strong>(Slab Class)으로 관리합니다.</p>\n<p><strong>Slab Class 구성:</strong></p>\n<ul>\n<li><strong>Class 1</strong>: 64 bytes 크기 칸 (작은 오토바이용)</li>\n<li><strong>Class 2</strong>: 68 bytes 크기 칸 (64 × 1.07)</li>\n<li><strong>Class 3</strong>: 73 bytes 크기 칸 (68 × 1.07)</li>\n<li>...</li>\n<li><strong>Class N</strong>: 1 MB 크기 칸 (대형 트럭용)</li>\n</ul>\n<p><strong>동작 원리:</strong></p>\n<p>저장할 데이터가 50 bytes라면:</p>\n<ol>\n<li>50 bytes를 담을 수 있는 <strong>가장 작은 Class</strong> 찾기 → Class 1 (64 bytes)</li>\n<li>Class 1의 빈 칸에 저장 (14 bytes는 낭비)</li>\n<li>Class 1의 빈 칸이 없으면 → 1MB 메모리를 새로 요청해서 64 bytes 칸으로 나눔</li>\n</ol>\n<p><strong>제거 정책 (LRU):</strong></p>\n<p>전체 메모리가 꽉 차면:</p>\n<ul>\n<li>새 50 bytes 데이터를 저장하려면 <strong>Class 1 내에서만</strong> 가장 오래된 데이터 제거</li>\n<li>Class 2, 3에 빈 공간이 많아도 사용 불가 (크기가 안 맞음)</li>\n</ul>\n<p><strong>문제점:</strong></p>\n<p>초기에는 작은 데이터가 많아서 Class 1에 메모리를 많이 할당했는데, 나중에 큰 데이터가 많아지면:</p>\n<ul>\n<li>Class 1은 빈 공간 많음 (낭비)</li>\n<li>Class N은 공간 부족 (히트율 하락)</li>\n<li>하지만 메모리를 Class 간에 옮길 수 없음!</li>\n</ul>\n<h4>적응형 할당자</h4>\n<p>기본 Slab Allocator의 문제(Class 간 메모리 이동 불가)를 해결하기 위해 <strong>메모리 재균형</strong> 메커니즘을 추가했습니다.</p>\n<p><strong>재할당이 필요한 상황 판단:</strong></p>\n<p>구체적인 예시:</p>\n<ul>\n<li><strong>Class 1 (64B)</strong>: 가장 오래된 데이터가 10분 전에 사용됨</li>\n<li><strong>Class N (1MB)</strong>: 가장 오래된 데이터가 1분 전에 사용됨 (계속 제거 중)</li>\n</ul>\n<p><strong>조건 1</strong>: Class N이 공간 부족으로 LRU 제거 중\n<strong>조건 2</strong>: Class N의 제거 대상(1분 전)이 Class 1의 LRU(10분 전)보다 <strong>20% 이상 최신</strong></p>\n<ul>\n<li>Class 1: 10분 = 600초</li>\n<li>Class N: 1분 = 60초</li>\n<li>60초는 600초보다 훨씬 최신 (90% 더 최신)</li>\n</ul>\n<p><strong>결론</strong>: Class N이 더 중요한 데이터를 제거하고 있음 → 메모리 재할당 필요</p>\n<p><strong>재할당 동작:</strong></p>\n<ul>\n<li>Class 1(빈 공간 많음)에서 1MB Slab을 빼앗아 Class N에게 할당</li>\n<li>Class N은 이제 더 많은 공간 확보</li>\n</ul>\n<p><strong>오픈소스와의 차이</strong></p>\n<p>오픈소스 커뮤니티는 Slab Class 간 제거율을 균형 잡는 유사한 할당자를 독립적으로 구현했습니다. Facebook의 알고리즘은 <strong>가장 오래된 아이템의 나이</strong>를 균형 잡는 데 초점을 맞춥니다.</p>\n<p>나이를 균형 잡는 것이 제거율을 조정하는 것보다 전체 서버에 대한 단일 글로벌 LRU 제거 정책을 더 잘 근사합니다.</p>\n<h3>임시 아이템 캐시 (Transient Item Cache)</h3>\n<p><strong>문제 상황:</strong></p>\n<p>실시간 이벤트(예: 라이브 스포츠 경기, 콘서트)가 있을 때:</p>\n<ul>\n<li>수백만 명이 동시에 \"실시간 점수\" 데이터 조회</li>\n<li>이 데이터는 30초마다 갱신 (30초 만료 시간 설정)</li>\n<li>이벤트 종료 후에는 아무도 조회하지 않음</li>\n</ul>\n<p><strong>기존 방식의 문제 (Lazy Eviction):</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[10:00] 실시간 점수 캐시 (만료: 30초 후)\n[10:00:30] 만료됨! 하지만 메모리에는 그대로 남아있음\n[10:01] 아무도 조회 안 함 → 만료 확인 안 함 → 메모리 낭비 계속\n[10:02] 아무도 조회 안 함 → 여전히 메모리 차지\n...\n[11:00] LRU 끝에 도달해야 비로소 삭제</code></pre></div>\n<p>이벤트가 끝났는데도 1시간 동안 메모리의 6%를 낭비!</p>\n<p><strong>해결 방법: Circular Buffer</strong></p>\n<p>시계처럼 돌아가는 원형 버퍼 (예: 3600개 버킷 = 1시간 분량):</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">현재 시각: 10:00:00\n\n버킷 인덱스:  [0] [1] [2] [3] ... [30] ... [3599]\n               ↑ 헤드 (현재 초)\n\n저장 시:\n- 데이터 A (만료: 10초 후) → 버킷[10]에 삽입\n- 실시간 점수 (만료: 30초 후) → 버킷[30]에 삽입\n- 데이터 B (만료: 100초 후) → 버킷[100]에 삽입\n\n매 초마다:\n[10:00:01] 헤드 이동 → 버킷[1] 삭제\n[10:00:02] 헤드 이동 → 버킷[2] 삭제\n...\n[10:00:10] 헤드 이동 → 버킷[10] 삭제 (데이터 A 정확히 10초 후 삭제!)\n...\n[10:00:30] 헤드 이동 → 버킷[30] 삭제 (실시간 점수 정확히 30초 후 삭제!)\n...\n[10:01:40] 헤드 이동 → 버킷[100] 삭제 (데이터 B 정확히 100초 후 삭제!)</code></pre></div>\n<p><strong>핵심</strong>: 각 버킷은 \"몇 초 후 만료\"를 나타내며, 헤드가 그 버킷에 도달하면 정확히 만료 시간이 된 것입니다.</p>\n<p><strong>저장 구조:</strong></p>\n<ol>\n<li><strong>Memcache 해시 테이블</strong>: 실제 데이터 저장 (key → value)</li>\n<li><strong>Circular Buffer 버킷</strong>: 해시 테이블 아이템의 <strong>포인터(참조)만</strong> 저장</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">해시 테이블:\nuser:1 → \"점수 데이터\" (메모리 주소: 0x1234)\n\nCircular Buffer 버킷[30]:\n→ 0x1234 (포인터만 저장)\n\n삭제 시:\n버킷[30] 도달 → 0x1234 주소의 데이터를 해시 테이블에서 삭제</code></pre></div>\n<p><strong>효과:</strong></p>\n<ul>\n<li>만료 즉시 메모리 해제 (1시간 기다릴 필요 없음)</li>\n<li>메모리 사용: 6% → 0.3% (20배 개선)</li>\n<li>히트율: 영향 없음 (어차피 만료된 데이터)</li>\n</ul>\n<h3>소프트웨어 업그레이드</h3>\n<p>업그레이드, 버그 수정, 임시 진단 또는 성능 테스트를 위해 빈번한 소프트웨어 변경이 필요할 수 있습니다.</p>\n<p><strong>문제점</strong></p>\n<p>Memcached 서버는 피크 히트율의 90%에 도달하는 데 몇 시간이 걸릴 수 있습니다. 결과적으로 Memcached 서버 세트를 업그레이드하는 데 12시간 이상이 걸릴 수 있으며, 그 결과 발생하는 데이터베이스 부하를 신중하게 관리해야 합니다.</p>\n<h4>공유 메모리 방식</h4>\n<p><strong>일반 메모리 vs 공유 메모리:</strong></p>\n<p><strong>일반 메모리 (프로세스 전용):</strong></p>\n<ul>\n<li>프로세스 A가 할당한 메모리는 프로세스 A만 사용</li>\n<li>프로세스 종료 시 메모리도 함께 삭제됨</li>\n</ul>\n<p><strong>System V 공유 메모리 (OS 관리 영역):</strong></p>\n<ul>\n<li>OS가 관리하는 특별한 메모리 영역</li>\n<li>여러 프로세스가 공유 가능</li>\n<li>프로세스 종료해도 메모리는 OS에 남아있음</li>\n</ul>\n<p><strong>Memcached 개선:</strong></p>\n<p>각 Memcached 서버에서 데이터를 저장할 때:</p>\n<p><strong>기존 방식 (일반 메모리):</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Memcached 프로세스 (PID: 1234)\n└─ 일반 메모리 할당\n   └─ user:1 → \"profile data\"\n   └─ user:2 → \"settings\"\n\n프로세스 종료 → 메모리 전부 삭제됨\n새 프로세스 시작 → 캐시 비어있음 (워밍업 12시간 필요)</code></pre></div>\n<p><strong>개선 방식 (공유 메모리):</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">OS 공유 메모리 영역 (ID: 9999)\n├─ user:1 → \"profile data\"\n├─ user:2 → \"settings\"\n└─ ...\n\nMemcached 프로세스 (PID: 1234) → 공유 메모리 9999에 접근\n프로세스 종료 → 공유 메모리는 OS에 유지됨\n새 프로세스 (PID: 5678) → 공유 메모리 9999에 접근 (데이터 그대로!)</code></pre></div>\n<p><strong>업그레이드 절차:</strong></p>\n<ol>\n<li>기존 Memcached 프로세스(PID: 1234) 종료</li>\n<li>OS의 공유 메모리(ID: 9999)는 그대로 유지</li>\n<li>새 버전 Memcached 프로세스(PID: 5678) 시작</li>\n<li>공유 메모리 9999 연결 → 모든 캐시 데이터 즉시 사용 가능</li>\n<li>워밍업 불필요 (히트율 90% 즉시 달성)</li>\n</ol>\n<h2>Memcache 워크로드 특성 분석</h2>\n<p>프로덕션에서 실행 중인 서버의 데이터를 사용하여 Memcache 워크로드를 특성화합니다.</p>\n<h3>웹 서버에서의 측정</h3>\n<p>소수의 사용자 요청에 대한 모든 Memcache 작업을 기록하고 Fanout, 응답 크기, 지연시간 특성을 분석합니다.</p>\n<h4>Fanout: 서버 접근 패턴</h4>\n<p><strong>Fanout이란?</strong> 하나의 페이지 요청을 처리하기 위해 접촉하는 Memcached 서버 개수</p>\n<p><strong>전체 페이지 요청</strong></p>\n<ul>\n<li><strong>56%</strong>: 20개 미만의 Memcached 서버 접촉</li>\n<li>대부분의 사용자 요청은 적은 양의 캐시된 데이터만 필요</li>\n<li>긴 꼬리 분포 존재</li>\n</ul>\n<p><strong>인기 있는 특정 페이지 (예: 뉴스피드)</strong></p>\n<p>All-to-All 통신 패턴을 명확히 보여줍니다:</p>\n<ul>\n<li><strong>대부분의 요청</strong>: 100개 이상의 서버 액세스</li>\n<li>수백 개의 Memcached 서버 액세스도 드물지 않음</li>\n</ul>\n<p><strong>의미:</strong></p>\n<ul>\n<li>뉴스피드 페이지는 수백 명 친구의 데이터를 조합</li>\n<li>친구들의 데이터가 서로 다른 Memcached 서버에 분산 저장됨</li>\n<li>따라서 한 페이지 요청이 100개 이상의 서버에 접촉 필요</li>\n<li><strong>단일 서버 장애도 여러 사용자에게 영향</strong> → 높은 가용성 필수</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8fe0ca963842f4b1b02e9cf3e16b31da/eb2af/figure9.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 63.92405063291139%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAACDUlEQVR42o2TW4/aQAyF8/9/TtXXPlRbiUrQ3cISIBAggYTcINcZcoHkdGwIWrRq1ZGOZhjiL/axowEdSF132z+K7lq+/9/VQesDV6sVqqpE215xvV7U3j4eq5sGaS5QFAJCShyTDG6QYL0PlSLYnjq7sYq7Quu6FqQsS5GmCZ9plVWN7T7A4M3AcGJibR8wGK/x5buOrz8WeHmzMF75MJ0YYSKRiYpjtTAM4HkeHGePJEkYttwe8G3wjolhc2aVynC6jaFbCTLZ/MMGVbLrOrBtC3VdQRQZbDfEy3Cugm6Z1pcWP2c+nKh4CqRs2nt1ZFnfAy2KIgSBD9d1kauyf88tJJm8w64K5nFJtMhXBuBzA3tpvu+BVBS5KjmGafv3hnR4M6NHZlzmI5v270AqmURNIeAxzhngn6Ty7cRnIQXK8sxTQNbQfj7LT6IJeXhIwNPpiOiUMWRkBJDVBU1dohASm80Gk8kYo9EQprni0SJw09S4XBoWA4ksRMFALwgQpwUWuxSmmzK4qioFFOqlNl5ffzF0On3HcmlgNptiPp9B16dYLOY3YF+7EMrDNIW+DaFvAvXGmjMg5Xn2JPKbEuh/0/zSHQP7wabUCUw+VqXkRlH2ZAPd0Znu6Dma3b6qKArZV887sA3ac5fAf9R1jd1uxztBKKgsS/aRlmVtIdUnGMex+iAcngrDWDDwDzkE4wrimBJrAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Fanout 분포\"\n        title=\"\"\n        src=\"/static/8fe0ca963842f4b1b02e9cf3e16b31da/f058b/figure9.png\"\n        srcset=\"/static/8fe0ca963842f4b1b02e9cf3e16b31da/c26ae/figure9.png 158w,\n/static/8fe0ca963842f4b1b02e9cf3e16b31da/6bdcf/figure9.png 315w,\n/static/8fe0ca963842f4b1b02e9cf3e16b31da/f058b/figure9.png 630w,\n/static/8fe0ca963842f4b1b02e9cf3e16b31da/40601/figure9.png 945w,\n/static/8fe0ca963842f4b1b02e9cf3e16b31da/eb2af/figure9.png 954w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4>응답 크기 분포</h4>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">통계:\n- 중간값: 135 bytes\n- 평균: 954 bytes\n\n특징:\n- 중간값(135B)과 평균(954B)의 큰 차이 = 아이템 크기가 매우 다양함\n- 그래프에서 특정 크기에 데이터가 집중됨:\n  - 피크 1: ~100 bytes (작은 단일 값들)\n  - 피크 2: ~200 bytes (중간 크기 데이터)\n  - 피크 3: ~600 bytes (목록/집합 데이터)\n\n해석 (구체적 예시):\n\n큰 아이템 (평균 954 bytes):\n- 친구 목록: [user1, user2, user3, ...] (수십~수백 개)\n- 뉴스피드 ID 목록: [post1, post2, ...] (여러 게시물 ID)\n- 댓글 목록 데이터\n\n작은 아이템 (중간값 135 bytes):\n- 단일 사용자 이름: \"John Doe\"\n- 좋아요 개수: \"42\"\n- 프로필 사진 URL: \"https://...\"\n- 단일 설정 값: {\"notifications\": true}\n\n의미:\n- Facebook은 두 가지 캐싱 전략을 혼용\n- 작은 개별 데이터 캐싱 (빠른 조회)\n- 큰 집합 데이터 캐싱 (DB 부하 감소)\n- Slab Allocator가 다양한 크기를 효율적으로 처리해야 함</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/585d219cb5528e47a15758bc9192c637/7ae9c/figure10.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 70.25316455696203%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAABUklEQVR42qVUi47CIBDs/3/jqVXPM7lWsS8ebWFk4GhrE8/cucmG3QLD7DI0QzAH5yxSHH0Zp/w3i+syhtaOOBz2kLILMcHTmJx5P/TeBwzetTFoOgmpFIzpMY5jBHTO+WRA09S43cQ0EVk7v0GjlSqMSycgD7HWH8ZDE8Pr9YLj8YCi+AZjLuKE0pGB6Xs4awP4szKXnpVlic3mA13XBoYsr5PaA+ofkL95JsQV5/NXAKsqEfojlXnK4CXg5VLidPpEXdcgOBvPMv8NWBQF9vscSknP8PY+oBAiXEpZFgGQJb8FGPTVG68lDYLzMrSZAaPgZxk95vYhn4TNhdQhyzZeX+xn2zbBefscOb/O+RDWh2YxsNPzItu6rpBe0Ha7CZtp/L7bbScVUm5sUyRll4CzpxakRQQZ/EWRDaVFdsk4x1at3vKrRkcjszzfvfiBONwBgVBMrzuOxcUAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"응답 크기 분포\"\n        title=\"\"\n        src=\"/static/585d219cb5528e47a15758bc9192c637/f058b/figure10.png\"\n        srcset=\"/static/585d219cb5528e47a15758bc9192c637/c26ae/figure10.png 158w,\n/static/585d219cb5528e47a15758bc9192c637/6bdcf/figure10.png 315w,\n/static/585d219cb5528e47a15758bc9192c637/f058b/figure10.png 630w,\n/static/585d219cb5528e47a15758bc9192c637/40601/figure10.png 945w,\n/static/585d219cb5528e47a15758bc9192c637/7ae9c/figure10.png 972w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4>지연시간 특성</h4>\n<p>웹서버가 Memcache에 데이터를 요청하고 받는 데 걸리는 시간을 측정합니다.</p>\n<p><strong>7일간 측정 (μs = 마이크로초 = 0.001밀리초)</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">프로덕션 부하 (실제 사용자 트래픽):\n- 중간값: 333 μs = 0.333 ms\n- p75 (75%): 475 μs = 0.475 ms\n- p95 (95%): 1.135 ms\n\n유휴 웹서버 (부하 없음):\n- 중간값: 178 μs = 0.178 ms\n- p75: 219 μs = 0.219 ms\n- p95: 374 μs = 0.374 ms</code></pre></div>\n<p><strong>차이의 원인:</strong></p>\n<p>p95에서 프로덕션(1.135ms)이 유휴(0.374ms)보다 3배 느린 이유:</p>\n<ol>\n<li><strong>큰 응답 처리</strong>: 954 bytes 평균 크기 데이터 전송/역직렬화</li>\n<li><strong>웹서버 부하</strong>: CPU 바쁠 때 스레드가 스케줄링 대기</li>\n</ol>\n<h3>Pool별 통계</h3>\n<p>4개의 Memcache Pool의 사용 패턴을 분석합니다:</p>\n<ul>\n<li><strong>Wildcard</strong>: 기본 풀 (모든 데이터)</li>\n<li><strong>App</strong>: 특정 앱 전용 풀 (게임, 채팅 등)</li>\n<li><strong>Replicated</strong>: 복제 풀 (인기 데이터)</li>\n<li><strong>Regional</strong>: 지역 풀 (공유 데이터)</li>\n</ul>\n<p><strong>측정 결과:</strong></p>\n<p>각 풀의 사용 패턴이 완전히 다릅니다:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/afb3feca92bdc86fea2ba1abb9448e31/bd9eb/table3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 19.62025316455696%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAx0lEQVR42j1QWRaCMAzk/gcEQWVxYSlFhNJSkDI24elHXjrJZDJN0MkWTV1h2z54Ph4YxwGtEGiaGkqNjIVoYO2MsnzCuY3xslj0/Ytjng0q3wN2BEWR45zE0HpC4jOR8zxDHJ/4Lf1CwiSc+Nq6LsiylJdR/XJOmBNFIQsHaXpFFIYwxjCBnBit0XUSnTyCnFlruY99/2P6yf1+87Mamddxzh0OaSMVq7LEu+8xKcWCw/DmaFuBaVJ8Bu0zCZJj4kjf+83S2b4O2CyxxOl9zAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Pool별 응답 크기 분포\"\n        title=\"\"\n        src=\"/static/afb3feca92bdc86fea2ba1abb9448e31/f058b/table3.png\"\n        srcset=\"/static/afb3feca92bdc86fea2ba1abb9448e31/c26ae/table3.png 158w,\n/static/afb3feca92bdc86fea2ba1abb9448e31/6bdcf/table3.png 315w,\n/static/afb3feca92bdc86fea2ba1abb9448e31/f058b/table3.png 630w,\n/static/afb3feca92bdc86fea2ba1abb9448e31/40601/table3.png 945w,\n/static/afb3feca92bdc86fea2ba1abb9448e31/78612/table3.png 1260w,\n/static/afb3feca92bdc86fea2ba1abb9448e31/bd9eb/table3.png 1442w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Replicated Pool (인기 데이터):\n- GET 비율: 가장 높음 (다른 풀의 2.7배)\n- 아이템 크기: 가장 작음 (단일 값)\n- 예: 사용자 이름, 프로필 사진 URL\n- 이유: 자주 읽히는 작은 데이터를 여러 서버에 복제\n\nApp Pool (앱 전용):\n- 데이터 churn: 높음 (자주 변경됨)\n- 미스율: 높음\n- 예: 게임 점수, 라이브 채팅 메시지\n- 이유: 몇 시간만 사용되고 사라지는 데이터\n\nRegional Pool (지역 공유):\n- 접근 빈도: 낮음\n- 메모리 효율: 높음\n- 예: 카테고리 데이터\n- 이유: 여러 클러스터가 공유</code></pre></div>\n<p><strong>의미:</strong> 워크로드 특성에 맞춰 Pool을 분리하면 각각 최적화 가능</p>\n<h3>무효화 지연시간</h3>\n<p>데이터 수정 후 캐시 무효화가 전파되는 속도를 측정합니다.</p>\n<p><strong>측정 방법:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[시작] 미국 웹서버가 프로필 사진 변경\n  ↓\n[1단계] 미국 마스터 DB에 쓰기 (user:1 = \"new.jpg\")\n  ↓\n[2단계] 미국 로컬 Memcache 무효화 (DELETE user:1)\n  ↓\n[3단계] 다른 Region 웹서버들이 user:1을 1초마다 조회\n  ↓\n[측정] 캐시 미스 발생 = 무효화 완료 시점 감지</code></pre></div>\n<p><strong>결과 (p95 기준):</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">마스터 Region (미국 내):\n- 같은 클러스터: 수 밀리초 (2~5ms)\n- 다른 Frontend Cluster: 수십 밀리초 (20~50ms)\n- 이유: 네트워크 홉 수 차이\n\n복제 Region (미국→유럽):\n- 수백 밀리초 (200~500ms)\n- 이유: MySQL 복제 지연 + mcsqueal 처리 + 네트워크 전송</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ba2f596b7978541f22889272e8bb666e/cc488/figure11.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 63.92405063291139%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAACbElEQVR42q2T22/SYBjG+du80AuTXWjihUu8nHMaY+aNy7wxzsU5I1nEqDOIhx3CPBHcZoa46QQGGxAdG0cZlJYzlMNghdLy+H2t4ESNNzZ50/br8/369H2faoA2/mdpms0GGg0BHMdCklr/2CCTktBuy+TuL0CGYcCyCSSTHCqVsiLuFalrAJcpwutn0DlkWVbqFyAFpVJJ1Gr7qFarRCBBJgD5kIsOMBTP4s3qNlLZPNG1uuDDbjWZTBq5XBbR6DcUiwWyuf1TSK6pgw4wxuXw5K0b2pl1TL+0w2LbgcMTgtgSu2gNy7KgRR3ST/aFGXz2hLEdZlGpHSgySZKU8x6bw9NFD+7M2DCsfYf+0QX0XXiIyzcMKJbKikZD+8cwcaTTKfDE4YojgLtGB0bvv8fNx1bsRriu4y5w1oYruhUMXDfh5CU9jp4ZQyqTU4GFQh60aC8pcM0dxvTrTdwiLoYmljA09gJrzl1FHCXAZ0teaOfsGNFZcHbMhFPDepw4N4l0rqACs9kMGUpKGUi5zCsOp+btuPrgAwbHzTh+Xo++QS3MFjviyTx5mQvjho+4eHsRp0eMODZwD0f6rxGHeRWYSKixiUTCKJWKcO9EYV77ggWLlzTegannqxiZnMW8yQouncXy+le8snphMG1AN/cJE4+WMa4zgi//6GGLTIhGpVTilWmKYhP1+j6Eeg31WhWCUAMNPw09nbogHKjrB/R5BWJTINXo5lfTG2Ba1LVr04VAMIgNpxNJ0hJRFBVomThxuVzY9fux5d5SNI3GH4C9f0gnezzPIxDwIxQKIhbbg8/nU1qkxqn1277vo0iwTA11VLcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"무효화 지연시간 분포\"\n        title=\"\"\n        src=\"/static/ba2f596b7978541f22889272e8bb666e/f058b/figure11.png\"\n        srcset=\"/static/ba2f596b7978541f22889272e8bb666e/c26ae/figure11.png 158w,\n/static/ba2f596b7978541f22889272e8bb666e/6bdcf/figure11.png 315w,\n/static/ba2f596b7978541f22889272e8bb666e/f058b/figure11.png 630w,\n/static/ba2f596b7978541f22889272e8bb666e/cc488/figure11.png 928w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><strong>의미:</strong></p>\n<ul>\n<li>같은 Region 내에서는 매우 빠른 무효화 (밀리초)</li>\n<li>다른 Region은 MySQL 복제 때문에 느림 (수백 밀리초)</li>\n<li>Remote Marker가 이 지연을 보완</li>\n</ul>\n<h2>규모별 우선순위의 변화</h2>\n<p>Facebook의 경험은 특정 규모에서 일부 품질이 다른 것보다 더 많은 노력을 필요로 한다는 것을 보여줍니다.</p>\n<p><strong>소규모 (단일 클러스터)</strong></p>\n<ul>\n<li>초점: 읽기 중심 워크로드, Wide fan-out</li>\n<li>최적화: 지연시간 감소, 부하 감소</li>\n<li>일관성: 상대적으로 쉬움 (복제 최소)</li>\n</ul>\n<p><strong>중간 규모 (Region 내 여러 클러스터)</strong></p>\n<ul>\n<li>초점: 데이터 복제, 메모리 효율성</li>\n<li>최적화: 무효화 전파, Regional Pool</li>\n<li>문제: 클러스터 간 데이터 일관성</li>\n</ul>\n<p><strong>대규모 (여러 Region)</strong></p>\n<ul>\n<li>초점: 지리적 분산, 일관성</li>\n<li>최적화: 복제 지연 처리, Remote Marker</li>\n<li>문제: 여러 Region 간 일관성 유지</li>\n<li>서버 수 증가: 통신 스케줄링의 중요성 급증</li>\n</ul>\n<p>성능, 효율성, 장애 내성, 일관성 모두 모든 규모에서 중요하지만, 각 규모에서 우선순위는 달라집니다.</p>","wordCount":{"words":3103},"frontmatter":{"title":"Facebook Memcached 아키텍처 (2탄) - 대규모 확장과 성능 최적화","date":"October 02, 2025","description":"Facebook Memcached의 지역 내/지역 간 확장 전략, 일관성 유지 메커니즘, 단일 서버 성능 최적화 기법을 분석합니다."}},"previous":{"fields":{"slug":"/cache-part1/"},"frontmatter":{"title":"Facebook Memcached 아키텍처 (1탄) - 기본 설계와 클러스터 내부 최적화"}},"next":{"fields":{"slug":"/mysql-part4/"},"frontmatter":{"title":"MySQL 엔진 아키텍처"}}},"pageContext":{"id":"c562831f-2840-545a-9e1c-fdd33dc31eeb","previousPostId":"7934a91e-9561-5a22-90e9-8ede258c0daf","nextPostId":"0f5161ec-2733-56c1-b9de-d2120698a099"}},"staticQueryHashes":["3257411868","3517523002"],"slicesMap":{}}